The series looks ok to me, even if I still am not a fan of the cookie.  I suspect the remaining users could easily embed the returned string  at the end of a structure, and get their data with container_of(). It  would complicate their unusual behavior for sure, but make the common  case much more understandable.   Oh well. I won't insist - it may be too painful to be worth it. And  it's a fairly separate issue anyway.   So no objections to this series.                 
Ugh, no, I had set that aside and then forgot all about it.   I'm not sure about 13/13.  I'm ok with it, but I'm not sure it's any  less confusing than the cookie was.   I like how it removes "put_link()" as a callback, but at the same time  I think it's even more abstract than the cookie was.   The main worry I have is that the naming is generic, but there's only  a single very specialized use for it. Do we expect other uses?   Because if not, I think it would be clearer if it was named to be more  concretely about putlink, and avoid the fact that it feels very  abstract.   Don't get me wrong - abstract generalized helper functions are cool.  But people aren't very abstract, and it tends to make for confusing  code when you aren't intimately familiar with the rules.                    
Normally, me doing an eighth release candidate means that there is  some unresolved issue that still needs more time to get fixed. This  time around, it just means that I want to make sure that everybody is  back from the holidays and there isn't anything pending, and that  people have time to get their merge window pull requests all lined up.  No excuses about how you didn't have time to get things done by the  time the merge window opened, now..   So it's in all the usual places, and it's pretty small. It's about  half drivers (mostly network drivers, but some rdma stuff and a  smattering of small other changes), with the rest being arch updates  (mainly sparc, arm), some general networking code, and some crypto  fixes.   But it's all really pretty small. Which is as it should be, with  holidays and just being late in the release cycle.   Expect final 4.4 next weekend, unless something very unexpected happens.                        Al Viro (1):        arm: fix handling of F_OFD_... in oabi_fcntl64()   Alexey Khoroshilov (1):        natsemi: add checks for dma mapping errors   Andrew Banman (1):        mm/memory_hotplug.c: check for missing sections in test_pages_in_a_zone()   Andrew Morton (1):        arch/x86/xen/suspend.c: include xen/xen.h   Andrey Ryabinin (1):        ipv6/addrlabel: fix ip6addrlbl_get()   BjÃrn Mork (1):        net: cdc_ncm: avoid changing RX/TX buffers on MTU changes   Dan Carpenter (1):        qlcnic: fix a loop exit condition better   Dan Streetman (1):        xfrm: dst_entries_init() per-net dst_ops   Daniele Palmas (2):        net: usb: cdc_ncm: Adding Dell DW5812 LTE Verizon Mobile Broadband Card        net: usb: cdc_ncm: Adding Dell DW5813 LTE AT&amp;T Mobile Broadband Card   David Howells (1):        KEYS: Fix race between read and revoke   David Miller (2):        6pack: Fix use after free in sixpack_close().        mkiss: Fix use after free in mkiss_close().   David Rivshin (2):        drivers: net: cpsw: fix RMII/RGMII mode when used with fixed-link PHY        drivers: net: cpsw: increment reference count on fixed-link PHY node   David S. Miller (2):        sparc: Add all necessary direct socket system calls.        sparc: Wire up mlock2 system call.   Devesh Sharma (4):        RDMA/ocrdma: Fix vlan-id assignment in qp parameters        RDMA/ocrdma: Dispatch only port event when port state changes        RDMA/ocrdma: Depend on async link events from CNA        RDMA/be2net: Remove open and close entry points   Dongdong Liu (1):        PCI: hisi: Fix hisi_pcie_cfg_read() 32-bit reads   Eugenia Emantayev (2):        net/mlx4_en: Remove dependency between timestamping capability  and service_task        net/mlx4_en: Fix HW timestamp init issue upon system startup   Florian Westphal (1):        netfilter: nft_ct: include direction when dumping NFT_CT_L3PROTOCOL key   Gary Wang (1):        drm/i915: increase the tries for HDMI hotplug live status checking   Guenter Roeck (1):        MIPS: VDSO: Fix build error with binutils 2.24 and earlier   Hannes Frederic Sowa (1):        ipv6: honor ifindex in case we receive ll addresses in router  advertisements   Heiko Carstens (1):        mm/vmstat: fix overflow in mod_zone_page_state()   Herbert Xu (2):        rhashtable: Kill harmless RCU warning in rhashtable_walk_init        crypto: algif_skcipher - Use new skcipher interface   Ido Schimmel (1):        switchdev: bridge: Pass ageing time as clock_t instead of jiffies   Jens Axboe (2):        block: add blk_start_queue_async()        null_blk: use async queue restart helper   Joe Stringer (1):        openvswitch: Fix template leak in error cases.   Johannes Berg (2):        iwlwifi: separate firmware version for 7260 devices        iwlwifi: mvm: protect RCU dereference in iwl_mvm_get_key_sta_id   Joseph Qi (1):        ocfs2: fix BUG when calculate new backup super   Julia Lawall (1):        drivers: net: cpsw: fix error return code   Junxiao Bi (1):        ocfs2: fix flock panic issue   Keith Busch (1):        block: Split bios on chunk boundaries    Torvalds (1):        Linux 4.4-rc8   Marcelo Ricardo Leitner (2):        sctp: use GFP_USER for user-controlled kmalloc        sctp: label accepted/peeled off sockets   Matan Barak (1):        IB/cma: cma_match_net_dev needs to take into account port_num   Matias BjÃrling (1):        lightnvm: wrong offset in bad blk lun calculation   Nicolai Stange (1):        net, socket, socket_wq: fix missing initialization of flags   Pablo Neira Ayuso (1):        netfilter: nf_tables: use skb-protocol instead of assuming  ethernet header   Paolo Abeni (1):        geneve: initialize needed_headroom   Pascal Speck (Iktek) (1):        ethernet:ti:cpsw: fix phy identification with multiple slaves on fixed-phy   Pravin B Shelar (1):        ipip: ioctl: Remove superfluous IP-TTL handling.   Sergei Shtylyov (1):        sh_eth: fix 16-bit descriptor field access endianness too   Simon Horman (1):        openvswitch: correct encoding of set tunnel action attributes   Sudip Mukherjee (2):        m32r: fix build failure        m32r: add io*_rep helpers   Venkat Duvvuru (1):        be2net: Avoid accessing eq object in be_msix_register routine, when i  0.   Vijay Pandurangan (1):        veth: donât modify ip_summed; doing so treats packets with bad  checksums as good.   Ville SyrjÃlÃ (1):        drm/i915: Unbreak check_digital_port_conflicts()   Vladimir Davydov (1):        mm: memcontrol: fix possible memcg leak due to interrupted reclaim   WANG Cong (1):        addrconf: always initialize sysctl table data   Wengang Wang (1):        IB/mlx4: Replace kfree with kvfree in mlx4_ib_destroy_srq   Xin Long (1):        sctp: sctp should release assoc when sctp_make_abort_user return  NULL in sctp_close   Yuval Mintz (1):        bnx2x: Prevent FW assertion when using Vxlan   xuejiufei (1):        ocfs2/dlm: clear migration_pending when migration target goes down
So it would have been good to have it in an -rc, but at the same time  I'm not particularly worried about this one.   It's not like it's complicated, and I'm assuming it got tested and  passed all our current test-cases (which are much more complete than  anything we've ever had historically).                        
I'd rather not be clever in order to save just a tiny amount of space  in the exception table, which isn't really criticial for anybody.   So I think Borislav's patch has the advantage of being pretty  straightforward and allowing arbitrary fixups, in case we end up  having localized special cases..                  
Actually, cc'ing lkml is still often a good idea, because it's a great  archiving point.   I know lots o people (and I am one) who are *not* on random mailing  lists that discuss particular subsystems, but that get lkml as an  auto-archived thing. Then, when cc'd, you see the back story - in a  way that you do *not* see with the random mailing list that was  specific to a particular subsystem.   There are also tools like patchworks that follow mailing lists - and  yes, it follows many different sublists, but not necessarily all.   Don't get me wrong: lkml is seldom - if ever - the _primary_ list. But  I would violently disagree with some kind of blanket "not really  necessary to CC linux-kernel" statement. It's still very useful  indeed, and it doesn't hurt to cc it for valid patches.                 
Was there confirmation this fixed the issue? Just verifying..                  
Oh, and Tetsuo claims that it needs a cc stable regardless, because  the commit that caused this to appear was marked for stable and  already got backported. Yes?                      
This seems sad for two reasons:    - it adds unnecessary overhead on non-pcid setups (32-bit being an  example of that)    - on pcid setups, wouldn't invpcid_flush_single_context() be better?   So on the whole I hate it.   Why isn't this something like   And yes, that means that we'd require X86_FEATURE_INVPCID in order to  use X86_FEATURE_PCID, but that seems fine.   Or is there some reason you wanted the odd flags version? If so, that  should be documented.                  
Ugh. I guess reading and writing cr3 has been optimized.   Can you check the timings? IOW, is it a win on SNB?   I think originally Intel only had two actual bits of process context  ID in the TLB, and it was meant to be used for virtualization or  something. Together with the hashing (to make it always appear as 12  bits to software - a nice idea but also means that the hardware ends  up invalidating more than software really expects), it may not work  all that well.   That _could_ explain why the original patch from intel didn't work.   I'm not convinced it is all that much faster. Of course, it's nicer on  non-preempt, but nobody seems to run things that way.   It's odd because it makes no sense for non-pcid (christ, I wish Intel  had just called it "asid" instead, "pcid" always makes me react to  "pci"), and I think it would make more sense to pair up the pcid case  with the invpcid rather than have those preemption rules here.                    
Interesting. There was reportedly (I never saw it) a test-patch to use  pcids inside of Intel a couple of years ago, and it never got outside  because it didn't make a difference.   Either things have changed (newer hardware with more pcids perhaps?)  or you did a better job at it.                 
They have always gotten hashed, and no the bits aren't real - hardware  doesn't actually have as many bits in the pcid as there are in cr3.                 
Have you checked all your callers? If the above makes a difference, it  really sounds like the caller has passed in a size of zero, resulting  in no cache flush, because the caller had incorrect ranges. The  additional clflushopt now flushes the previous cacheline that wasn't  flushed correctly before.   That "size was zero" thing would explain why changing the loop to "p  = vend" also fixes things for you.   IOW, just how sure are you that all the ranges are correct?                     
How do you know it was written by the GPU?   Maybe it's a memory ordering issue on the GPU. Say it writes something  to memory, then sets the "I'm done" flag (or whatever you check), but  because of ordering on the GPU the "I'm done" flag is visible before.   So the reason you see the old content may just be that the GPU writes  are still buffered on the GPU. And you adding a clflushopt on the same  address just changes the timing enough that you don't see the memory  ordering any more (or it's just much harder to see, it might still be  there).   Maybe the reason you only see the problem with the last cacheline is  simply that the "last" cacheline is also the last that was written by  the GPU, and it's still in the GPU write buffers.   Also, did you ever print out the value of clflush_size? Maybe we just  got it wrong and it's bogus data.                       
Ok. So assuming the GPU flushes are supposed to work, it should be all good.   Odd.   We have an entirely unrelated discussion about the value of "mfence"  as a memory barrier.   Mind trying to just make the memory barrier (in  arch/x86/include/asm/barrier.h) be a locked op instead?   The docs say "Executions of the CLFLUSHOPT instruction are ordered  with respect to fence instructions and to locked read-modify-write  instructions; ..", so the mfence should be plenty good enough. But  nobody sane uses mfence for memory ordering (that's the other  discussion we're having), since a locked rmw instruction is faster.   So maybe it's a CPU bug. I'd still consider a GPU memory ordering bug   experience), but since you're trying odd things anyway, try changing  the "mfence" to "lock; addl $0,0(%%rsp)" instead.   I doubt it makes any difference, but ..               
Actually, I think it's explainable.   It's wrong to do the clflush *after* the GPU has done the write, which  seems to be what you are doing.   Why?   If the GPU really isn't cache coherent, what can happen is:    - the CPU has the line cached    - the GPU writes the data    - you do the clflushopt to invalidate the cacheline    - you expect to see the GPU data.   Right?   Wrong. The above is complete crap.   Why?   Very simple reason: the CPU may have had the cacheline dirty at some  level in its caches, so when you did the clflushopt, it didn't just  invalidate the CPU cacheline, it wrote it back to memory. And in the  process over-wrote the data that the GPU had written.   Now you can say "but the CPU never wrote to the cacheline, so it's not  dirty in the CPU caches". That may or may not be trie. The CPU may  have written to it quite a long time ago.   So if you are doing a GPU write, and you want to see the data that the  GPU wrote, you had better do the clflushopt long *before* the GPU ever  writes to memory.   Your pattern of doing "flush and read" is simply fundamentally buggy.  There are only two valid CPU flushing patterns:    - write and flush (to make the writes visible to the GPU)    - flush before starting GPU accesses, and then read   At no point can "flush and read" be right.   Now, I haven't actually seen your code, so I'm just going by your  high-level description of where the CPU flush and CPU read were done,  but it *sounds* like you did that invalid "flush and read" behavior.                    
I don't think there are *any* architectural guarantees.   I suspect that a real serializing instruction should do it. But I  don't think even that is guaranteed.   Non-coherent IO is crazy. I really thought Intel had learnt their  lesson, and finally made all the GPU's coherent. I'm afraid to even  ask why Chris is actually working on some sh*t that requires clflush.   In general, you should probably do something nasty like    - flush before starting IO that generates data (to make sure you have  no dirty cachelines that will write back and mess up)    - start the IO, wait for it to complete    - flush after finishing IO that generates the data (to make sure you  have no speculative clean cachelines with stale data)    - read the data now.   Of course, what people actually end up doing to avoid all this is to  mark the memory noncacheable.   And finally, the *correct* thing is to not have crap hardware, and  have IO be cache coherent. Things that don't do that are shit. Really.                    
Hmm. Good point.   Ok, all the symptoms just say "writes from GPU are delayed and out of order".   Do you have access to the GPU hardware people?   I thought that all the modern Intel GPU's are cache-coherent. If this  is some castrated chip where coherence is removed (perhaps because it  is not working? perhaps config setting?) maybe it needs some extra  ghardware setting to make the GPU "flush" operation actually do  something. In a cache-coherent model, a flush could/should be a noop,  so maybe the hardware is set for that kind of "flush does nothing"  behavior.   Or maybe the GPU is just a buggy pile of crap.               
No. This is much too late for this kind of hackery. That second patch  in particular is both subtle and ugly, and is messing with lockdep.   No way will I take something like this the last fay before a release.   It's not even a regression, nor did you send me anything at all for  this release. Trying to sneak something in just before 4.4 is not ok.                        
No, I definitely don't want anything now unless it's a major  regression or security issue. Other stuff can wait until the merge  window and perhaps be marked for stable if required. That way they'll  get testing.                 
Nothing untoward happened this week, so Linux-4.4 is out in all the  usual  places.   The changes since rc8 aren't big. There's about one third arch  updates, one third drivers, and one third "misc" (mainly some core  kernel and networking), But it's all small. Notable might be  unbreaking the x86-32 "sysenter" ABI, when somebody  (*cough*android-x86*cough*) misused it by not using the vdso and  instead using the instruction directly.   Full shortlog appended for people who care or are just curious.   And with this, the merge window for 4.5 is obviously open, even if I  won't start actually pulling until tomorrow.                         Alan Cox (1):        mkiss: fix scribble on freed memory   Andrea Arcangeli (1):        firmware: dmi_scan: Fix UUID endianness for SMBIOS = 2.6   Andrey Ryabinin (1):        sched/fair: Fix multiplication overflow on 32-bit systems   Andy Lutomirski (2):        x86/entry: Fix some comments        x86/entry: Restore traditional SYSENTER calling convention   Arnaldo Carvalho de Melo (2):        perf list: Add support for PERF_COUNT_SW_BPF_OUT        perf list: Robustify event printing routine   Ashok Raj (1):        x86/mce: Ensure offline CPUs don't participate in rendezvous process   Ashutosh Dixit (1):        dmaengine: Revert "dmaengine: mic_x100: add missing spin_unlock"   Bard Liao (1):        ASoC: rt5645: add sys clk detection   Ben Skeggs (1):        drm/nouveau/gr/nv40: fix oops in interrupt handler   Boris Ostrovsky (1):        x86/xen: Avoid fast syscall path for Xen PV guests   Brian Norris (3):        mtd: fix cmdlinepart parser, early naming for auto-filled MTD        mtd: spi-nor: fix Spansion regressions (aliased with Winbond)        mtd: spi-nor: fix stm_is_locked_sr() parameters   Charles Keepax (1):        ASoC: Use nested lock for snd_soc_dapm_mutex_lock   Chris Metcalf (1):        tile: provide CONFIG_PAGE_SIZE_64KB etc for tilepro   Colin Ian King (1):        ftrace/scripts: Fix incorrect use of sprintf in recordmcount   Daniel J Blueman (1):        x86/numachip: Fix NumaConnect2 MMCFG PCI access   David Ahern (1):        net: Propagate lookup failure in l3mdev_get_saddr to caller   David Vrabel (1):        x86/paravirt: Prevent rtc_cmos platform device init on PV guests   Florian Westphal (1):        connector: bump skb-users before callback invocation   Francesco Ruggeri (1):        net: possible use after free in dst_release   Geert Uytterhoeven (1):        iommu/ipmmu-vmsa: Don't truncate ttbr if LPAE is not enabled   Hannes Frederic Sowa (1):        bridge: Only call /sbin/bridge-stp for the initial network namespace   Hui Wang (1):        ALSA: hda - Add keycode map for alc input device   Insu Yun (2):        qlcnic: correctly handle qlcnic_alloc_mbx_args        cxgb4: correctly handling failed allocation   Jens Axboe (1):        Revert "block: Split bios on chunk boundaries"   John Fastabend (1):        net: sched: fix missing free per cpu on qstats   Kailang (1):        ALSA: hda - Add mic mute hotkey quirk for Lenovo ThinkCentre AIO   Kees Cook (1):        ACPI / property: avoid leaking format string into kobject name   Kristian Evensen (1):        net: qmi_wwan: Add WeTelecom-WPD600N    Torvalds (1):        Linux 4.4    Walleij (2):        ARM: nomadik: set latencies to 8 cycles        ARM: versatile: fix MMC/SD interrupt assignment   Martin K. Petersen (1):        sd: Reject optimal transfer length smaller than page size   Michael Petlan (2):        perf buildid-list: Show running kernel build id fix        perf buildid-list: Fix return value of perf buildid-list -k   Michal Hocko (1):        vmstat: allocate vmstat_wq before it is used   NeilBrown (1):        async_tx: use GFP_NOWAIT rather than GFP_IO   Nikesh Oswal (1):        ASoC: arizona: Fix bclk for sample rates that are multiple of 4kHz   One Thousand Gnomes (1):        6pack: fix free memory scribbles   Paolo Bonzini (1):        kvm: x86: only channel 0 of the i8254 is linked to the HPET   Peter Zijlstra (3):        perf: Fix race in perf_event_exec()        perf: Fix race in swevent hash        sched/core: Fix unserialized r-m-w scribbling stuff   Qiu Peiyang (1):        tracing: Fix setting of start_index in find_next()   Rabin Vincent (2):        net: filter: make JITs zero A for SKF_AD_ALU_XOR_X        ARM: net: bpf: fix zero right shift   Rainer Weikusat (1):        af_unix: Fix splice-bind deadlock   Rameshwar Prasad Sahu (1):        dmaengine: xgene-dma: Fix double IRQ issue by setting  IRQ_DISABLE_UNLAZY flag   Richard Cochran (1):        PCI: dra7xx: Mark driver as broken   Robin Murphy (3):        iommu/dma: Add some missing #includes        iommu/dma: Avoid unlikely high-order allocations        iommu/dma: Use correct offset in map_sg   Roman Volkov (1):        dts: vt8500: Add SDHC node to DTS file for WM8650   Sebastian Andrzej Siewior (1):        sched/core: Reset task's lockless wake-queues on fork()   Sergey Senozhatsky (1):        sched/core: Check tgid in is_global_init()   Shrikrishna Khare (1):        Driver: Vmxnet3: Fix regression caused by 5738a09   Steven Rostedt (Red Hat) (1):        ftrace/module: Call clean up function when module init fails early   Thomas Gleixner (1):        genirq: Prevent chip buslock deadlock   Timo Sigurdsson (2):        ARM: Fix broken USB support in sunxi_defconfig        ARM: Fix broken USB support in multi_v7_defconfig for sunxi devices   Tony Lindgren (1):        ARM: OMAP2+: Fix onenand rate detection to avoid filesystem corruption   Vinod Koul (2):        ASoC: Intel: Skylake: Revert previous broken fix memory leak fix        ASoC: Intel: Skylake: Fix the memory leak   Wang Nan (3):        perf hists browser: Add NULL pointer check to prevent crash        perf hists browser: Reset selection when refresh        perf hists browser: Fix segfault if use symbol filter in cmdline   Yuchung Cheng (1):        tcp: fix zero cwnd in tcp_cwnd_reduction   hayeswang (1):        r8152: add reset_resume function
Hmm. Is it really called for to rename all the docs etc  "cgroup-legacy", considering that it's the one that is actually used,  and the new one isn't even ready yet?   That seems very questionable.                    
The merge window is open, so I started looking at this that I had  ignored as being too late last time..   So at a minimum, I'd like a sign-off for the patch. But also, can you  describe how to actually trigger the problem? Is this actually  triggerable without an ICE?                   
And I think that's insufficient *also*.   What you actually want is "sync_file_range()", with the full set of arguments.   Yes, really. Sometimes you want to start the writeback, sometimes you  want to wait for it. Sometimes you want both.   For example, if you are doing your own manual write-behind logic, it  is not sufficient for "wait for data". What you want is "start IO on  new data" followed by "wait for old data to have been written out".   I think this only strengthens my "stop with the idiotic  special-case-AIO magic already" argument.  If we want something more  generic than the usual aio, then we should go all in. Not "let's make  more limited special cases".                 
So is openat. So is readahead.   My point is that this idiotic "let's expose special cases" must end.  It's broken. It inevitably only exposes a subset of what different  people would want.   Making "aio_read()" and friends a special interface had historical  reasons for it. But expanding willy-nilly on that model does not.                  
Oh, I don't disagree with that. I think it should be exposed, my point  was that that too was not enough.   I don't see why you argue. You said "that's not enough". And I jjust  said that your expansion wasn't sufficient either, and that I think we  should strive to expand things even more.   And preferably not in some ad-hoc manner. Expand it to *everything* we can do.   That would likely be the simplest approach, yes.   There's a few arguments against it, though:    - doing the indirect system call thing does end up being  architecture-specific, so now you do need the AIO code to call into  some arch wrapper.      Not a huge deal, since the arch wrapper will be pretty simple (and  we can have a default one that just returns ENOSYS, so that we don't  have to synchronize all architectures)    - the aio interface really is horrible crap. Really really.      For example, the whole "send signal as a completion model" is so  f*cking broken that I really don't want to extend the aio interface  too much. I think it's unfixable.   So I really think we'd be *much* better off with a new interface  entirely - preferably one that allows the old aio interfaces to fall  out fairly naturally.   Ben mentioned lio_listio() as a reason for why he wanted to extend the  AIO interface, but I think it works the other way around: yes, we  should look at lio_listio(), but we should look at it mainly as a way  to ask ourselves: "can we implement a new aynchronous system call  submission model that would also make it possible to implement  lio_listio() as a user space wrapper around it".   For example, if we had an actual _good_ way to queue up things, you  could probably make that "struct sigevent" completion for lio_listio()  just be another asynchronous system call at the end of the list - a  system call that sends the completion signal.  And the aiocb_list[]  itself? Maybe those could just be done as normal (individual) aio  calls (so that you end up having the aiocb that you can wait on with  aio_suspend() etc).   But then people who do *not* want the crazy aiocb, and do *not* want  some SIGIO or whatever, could just fire off asynchronous system calls  without that cruddy interface.   So my argument is really that I think it would be better to at least  look into maybe creating something less crapulent, and striving to  make it easy to make the old legacy interfaces be just wrappers around  a more capable model.   And hey, it may be that in the end nobody cares enough, and the right  thing (or at least the prudent thing) to do is to just pile the crap  on deeper and higher, and just add a single IOCB_CMD_SYSCALL  indirection entry.   So I'm not dismissing that as a solution - I just don't think it's a  particularly clean one.   It does have the advantage of likely being a fairly simple hack. But  it smells like a hack.                   
Hmm. Thinking more about this makes me worry about all the system call  versioning and extra work done by libc.   At least glibc has traditionally decided to munge and extend on kernel  system call interfaces, to the point where even fairly core data   kernel as they do to user space.   So with that worry, I have to admit that maybe a limited interface -  rather than allowing arbitrary generic async system calls - might have  advantages. Less room for mismatches.   I'll have to think about this some more.                     
So I think this is ridiculously ugly.   AIO is a horrible ad-hoc design, with the main excuse being "other,  less gifted people, made that design, and we are implementing it for  compatibility because database people - who seldom have any shred of  taste - actually use it".   But AIO was always really really ugly.   Now you introduce the notion of doing almost arbitrary system calls  asynchronously in threads, but then you use that ass-backwards nasty  interface to do so.   Why?   If you want to do arbitrary asynchronous system calls, just *do* it.  But do _that_, not "let's extend this horrible interface in arbitrary  random ways one special system call at a time".   In other words, why is the interface not simply: "do arbitrary system  call X with arguments A, B, C, D asynchronously using a kernel  thread".   That's something that a lot of people might use. In fact, if they can  avoid the nasty AIO interface, maybe they'll even use it for things  like read() and write().   So I really think it would be a nice thing to allow some kind of  arbitrary "queue up asynchronous system call" model.   But I do not think the AIO model should be the model used for that,  even if I think there might be some shared infrastructure.   So I would seriously suggest:    - how about we add a true "asynchronous system call" interface    - make it be a list of system calls with a futex completion for each  list entry, so that you can easily wait for the end result that way.    - maybe (and this is where it gets really iffy) you could even pass  in the result of one system call to the next, so that you can do  things like          fd = openat(..)         ret = read(fd, ..)      asynchronously and then just wait for the read() to complete.   and let us *not* tie this to the aio interface.   In fact, if we do it well, we can go the other way, and try to  implement the nasty AIO interface on top of the generic "just do  things asynchronously".   And I actually think many of your kernel thread parts are good for a  generic implementation. That whole "AIO_THREAD_NEED_CRED" etc logic  all makes sense, although I do suspect you could just make it  unconditional. The cost of a few atomics shouldn't be excessive when  we're talking "use a thread to do op X".   What do you think? Do you think it might be possible to aim for a  generic "do system call asynchronously" model instead?   I'm adding Ingo the to cc, because I think Ingo had a "run this list  of system calls" patch at one point - in order to avoid system call  overhead. I don't think that was very interesting (because system call  overhead is seldom all that noticeable for any interesting system  calls), but with the "let's do the list asynchronously" addition it  might be much more intriguing. Ingo, do I remember correctly that it  was you? I might be confused about who wrote that patch, and I can't  find it now.                  
Nope. No can do.   I get a build error:     drivers/regulator/max8973-regulator.c:506:4: error:  âTHERMAL_DEVICE_EVENT_THRESHOLDâ undeclared   and grepping around for this that is not some merge error: even in  your tree (before being merged into mine), that thing simply does not  exist except in that one place:     [torvalds@i7 linux]$ git grep THERMAL_DEVICE_EVENT_THRESHOLD 2986a09d8    2986a09d8:drivers/regulator/max8973-regulator.c:   and that's it.   So this tree clearly can never have worked, and never have compiled.   Consider yourself cursed at.                          
Side note: I'm dropping your other pull request without even bothering  testing it, since you clearly didn't.   Don't bother re-sending until you have tested your pull requests  better and have had them in linux-next for a while.                         
I've so far merged media/v4.5-1, not yet this (media/v4.5-2)..                 
Your pull-request script is doing something funky and duplicated the  summary, shortlog and diffstat..   Pulled, but thought I'd mention it.               
That's not safe in general. gcc might be using its redzone, so doing  xchg into it is unsafe.   But..   interactions (ie some operations may have different dynamic behavior  when the write buffers are busy etc), but as a baseline for "how fast  can things go" the stupid raw loop is fine. And while the xchg into  the redzoen wouldn't be acceptable as a real implementation, for  timing testing it's likely fine (ie you aren't hitting the problem it  can cause).   Note that we never actually *use* lfence/sfence. They are pointless  instructions when looking at CPU memory ordering, because for pure CPU  memory ordering stores and loads are already ordered.   The only reason to use lfence/sfence is after you've used nontemporal  stores for IO. That's very very rare in the kernel. So I wouldn't  worry about those.   But yes, it does sound like mfence is just a bad idea too.   No.   I think the only issue is that there has never been any real reason  for CPU designers to try to make mfence go particularly fast. Nobody  uses it, again with the exception of some odd loops that use  nontemporal stores, and for those the cost tends to always be about  the nontemporal accesses themselves (often to things like GPU memory  over PCIe), and the mfence cost of a few extra cycles is negligible.   The reason "lock ; add $0" has generally been the fastest we've found  is simply that locked ops have been important for CPU designers.   So I think the patch is fine, and we should likely drop the use of mfence..                         
We should drop it, yes. We dropped support for CONFIG_X86_OOSTORE  almost two years ago. See commit 09df7c4c8097 ("x86: Remove  CONFIG_X86_OOSTORE") and it was questionable for a long time even  before that (perhaps ever).   So the comment is stale.   We *do* still use the non-nop rmb/wmb for IO barriers, but even that  is generally questionable. See our "copy_user_64.S" for an actual use  of "movnt" followed by sfence. There's a couple of other cases too. So  that's all correct, but the point is that when we use "movnt" we don't  actually use "wmb()", we are doing assembly, and the assembly should  just use sfence directly.   So it's actually very questionable to ever make even the IO  wmb()/rmb() functions use lfence/sfence. They should never really need  it.   But at the same time, I _really_ don't think we care enough. I'd  rather leave those non-smp barrier cases alone as historial unless  somebody can point to a case where they care about the performance.   We also do have the whole PPRO_FENCE thing, which we can hopefully get  rid of at some point too.                    
I suspect it could go either way. You want a small constant (for the  isntruction size), but any small constant is likely to be within the  current stack frame anyway. I don't think 0(%rsp) is particularly  likely to have a spill on it right then and there, but who knows..   And 64(%rsp) is  possibly going to be cold in the L1 cache, especially  if it's just after a deep function call. Which it might be. So it  might work the other way.   So my guess would be that you wouldn't be able to measure the   any noise.   But numbers talk, bullshit walks. It would be interesting to be proven wrong.                    
Well, that's with the busy loop and one set of code generation. It  doesn't show the "oops, deeper stack isn't even in the cache any more  due to call chains" issue.   But yes:   I think a negative offset might work very well. Partly exactly   kernel, we'll never have any live stack frame accesses under the stack  pointer, so "-4(%rsp)" sounds good to me. There should never be any  pending writes in the write buffer, because even if it *was* live, it  would have been read off first.   Yeah, it potentially does extend the stack cache footprint by another  4 bytes, but that sounds very benign.   addl $0,-4(%rsp)" in the kernel for x86-64, and remove the alternate  for x86-32.   I'd still want to see somebody try to benchmark it. I doubt it's  noticeable, but making changes because you think it might save a few  cycles without then even measuring it is just wrong.                    
So I can pretty much guarantee that it shouldn't regress from a  correctness angle, since we rely *heavily* on locked instructions  being barriers, in locking and in various other situations.   Indeed, much more so than we ever rely on "smp_mb()". The places that  rely on smp_mb() are pretty few in the end.   So I think the only issue is whether sometimes "mfence" might be  faster. So far, I've never actually heard of that being the case. The  fence instructions have always sucked when I've seen them.   But talking to the hw people about this is certainly a good idea regardless.                    
It's probably a good idea to add one.   Historically, gcc doesn't need one on x86, and always considers flags  clobbered. We are probably missing the cc clobber in a *lot* of places  for this reason.   But even if not necessary, it's probably a good thing to add for  documentation, and in case gcc semantcs ever change.                     
So before you do that, can you explain in what cases fuse just wants  to pass through the IO?   Why aren't such cases just using unionfs or something?   In other words, I think that patch needs an explanation for the                  
So I think these are valid use-cases, and I just think that they should    (a) be documented in the commit message as explanations of why people  would do this/    (b) not be called "stacked", because that tends to have some other  connotations to fs people.   I don't know what a better term would be, but you yourself used "pass  through". Maybe that (perhaps together with a clarification that it's  a per-file thing) might work fine.   Btw, why is mmap not passed through? That sounds fairly simple and  straightforward, I'm not seeing why it would be missing.                    
Why would they care?   Also, I don't think you actually need to change vm_file - we have this  whole notion of "inode-i_data" vs "inode-i_mapping".   So I think you could set the "i_mapping" of the fuse inode to be the  i_mapping of the passed-through-to inode, and it should just work.   And no, I didn't look into this very deeply, and maybe there is some  annoying detail that would make that not work well. But that's part of  the whole point of the i_mapping indirection: so that you can share  the page cache when you have two separate anchor points. I think coda  uses it for the local caching, and block devices use it to not have  mapping aliases between different inodex that all are the same block  device.                    
Hans, Mauro,   forwarding an email from Kikim with new USB ID's for the 880NC webcam.   Kikim, you really should send the patch as a single patch, and with  the appropriate sign-off. See Documentation/SubmittingPatches. Also,  please send to the right people: you can get that with   (and you can also see them from this email).                  
That makes no sense. The rc cycle for 4.4 was _longer_ than usual, not  unusually short. Exactly because I expected people to be off a bit  over the holidays. And while I have occasionally been off by a few  days for individual rc releases, every single 4.4 rc was on a Sunday  afternoon.   I've pulled the tree, but am baffled by your pull request.                    
Yeah, that would do it.   Al, did you check any other filesystems do this?   Also, I'm wondering if we should perhaps revert the "don't use  highmem". Do we actually have examples of running out of kmaps? Do we  care?                   
Why couldn't we just do that in the RCU walker? kmap should be fine..   That said, as long as you think it's ok now, I guess I don't care.  Having some sanity testing in __add_to_page_cache_locked might be a  good safety net.                
Al,   _please_ learn to be more careful about your pull requests.   This one is garbage.   Why?   You ask me to pull from the wrong source. You ask me to pull from      git://git.kernel.org/pub/scm/linux/kernel/git/viro/vfs   but that is some random state from January 2014. Two years ago.   What you actually *meant* was apparently the "for-linus" branch, since  that matches the shortlog and diffstat. But that's not what your pull  request asked me to pull.   This is not the first time. You seem to either use buggy scripts, or  do this (wrong) by hand. Please fix whatever it is, so that I don't  have to go look or guess after I notice that I pulled crap.                       
You could try "git request-pull". It _used_ to have somewhat similar  issues, especially when the local branch had not made it to the remote  point yet, but it should be good now. It actually warns if the remote  name you give doesn't contain what the local branch contanis etc.   "git symbolic-ref HEAD" will show what HEAD points to. That's probably  what you'd want..   Not that there is anything *wrong* with looking at "git branch"  output, but that's really meant to be more human-readable than for  scripting.                
A missing branch name is the same as HEAD, so:   If you say "no branch name", then it assumes that it's head in your  local and remote repositories.   So it's expected. It also *should* warn about the fact that the remote  repository HEAD does not match. Does it not do that?   Anyway, in general, you should always use a branch-name for "git  request-pull", since you use branches. The "no branch name" is really  only meant for the very original kind of git workflow where you don't  use branches at all. Some people still do that (David Miller seems to  prefer separate repositories over multiple branches, for example), but  it's starting to be unusual.   Also, if your local branch is named differently from your remote one,  you need to use the same format as you would have done for "git push"  to push it out, so you'd do       git request-pull remote-repo local-branch-name:remote-branch-name   but quite frankly, I wouldn't recommend that workflow. I think it's  too prone to mistakes.   So what I always do on all my repositories is that "origin" ends up  being the public thing, and then I have a separate set of things I  push to.   Now, the reason I do that is that pushing is different from pulling,  not only because of the whole security thing, but because I push to  multiple repos.   So my .gti/config looks roughly like this:   [remote "origin"]      url = git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git   [branch "master"]      remote = origin      merge = refs/heads/master   [remote "all"]      url = ra.kernel.org:/pub/scm/linux/kernel/git/torvalds/linux      url = git@xxxxxxxxxx:torvalds/linux.git   and that means that when I pull from my own remote (which I actually  do when I travel - it's hoe I synchronize my laptop and desktop), I  use origin. And when I push, I do "git push all", and it pushes to  both kernel.org and to the github "mirror".   And a plain "git push" simply won't work, which is fine.                     
The drm parts also introduce a new warning:     drivers/gpu/drm/i915/intel_display.c:5232:0: warning:  "for_each_power_domain" redefined    drivers/gpu/drm/i915/i915_drv.h:312:0: note: this is the location of  the previous definition   which I'm leaving alone because I'm hoping that it will just magically  fix itself when I get the full drm pull.   But I wanted to mention it, just to make sure that it _does_ get fixed.             
Good luck with that.   It does seem to fix it.   It replaces it with this one, though:     drivers/gpu/drm/vc4/vc4_validate.c: In function âvalidate_gl_shader_recâ:    drivers/gpu/drm/vc4/vc4_validate.c:864:12: warning: format â%dâ  expects argument of type âintâ, but argument 4 has type âsize_t {aka  long unsigned int}â [-Wformat=]   I'm assuming it has mainly been developed for 32-bit targets, and is  just enabled on x86-64 for compile testing. But the right thing to use  for size_t is "%zu".                     
Al, should I take this directly, or is it coming through your tree?                
It was just pulled because I wasn't 100% sure I wanted the extra  indirection. Oh well, pulled now.   One question:    - the arch/sh/ part of the pacth looks dubious. Why does it do that      despite the commit log saying it's done by asm-generic?   I haven't pushed out yet, my allmodconfig sanity-check build is still going..                         
I think we should just make it distro-specific rather than claiming it  is generic (and inevitably failing).   So we could have a config option for SYSTEMD, which selects stuff  systemd wants, and then distros that use systemd can select that etc.   It shouldn't be about just bootability either. Some of the networking  options end up being security-critical (ie your firewall might not  work if you don't have the right options enabled, leaving you wide  open after you boot).   Done right, you should be able to    (a) select your CPU (and things like "do you want virtualization etc")   (b) select your distro   (c) select your drivers   and pretty much be done with it.               
Sorry about the delay, with the merge window and me being sick for a  couple of days I didn't get around to this.   After thinking it over some more, I guess I'm ok with your approach.  The table-driven patch makes me a bit happier, and I guess not very  many people end up ever wanting to do async system calls anyway.   Are there other users outside of Solace? It would be good to get comments..               
I was more wondering about the new interfaces, making sure that the  feature set actually matches what people want to do..   That said, I also agree that it would be interesting to hear what the  performance impact is for existing performance-sensitive users. Could  we make that "aio_may_use_threads()" case be unconditional, making  things simpler?             
I assume that in this case it's simply that    - max_sectors is some odd number in sectors (ie 65535)    - the block size is larger than a sector (ie 4k)    - the device probably doesn't even have any silly chunk size issue  (so chunk_sectors is zero).   and because the block size is 4k, no valid IO can ever generate  anything but 4k-aligned IO's, and everything is fine.   Except now the "split bios" patch will split blindly at the  max_sectors size, which is pure and utter garbage, since it doesn't  take the minimum block size into account.   Also, quite frankly, I think that whole "split bios" patch is garbage *anyway*.   The thing is, the whole "blk_max_size_offset()" use there is broken.  What I think it _should_ do is:    (a) check against max sectors like it used to do:    (b) completely separately, and _independently_ of that max sector  check, it should check against the "chunk_sectors" limit if it exists.   instead, it uses that nasty blk_max_size_offset() crap, which is  broken because it's confusing, but also because it doesn't honor  max_sectors AT ALL if there is a chunking size.   So I think chunking size should be independent of max_sectors. I could  see some device that has some absolute max sector size, but that  _also_ wants to split so that the bio never crosses a particular chunk  size (perhaps due to RAID, perhaps due to some internal device block  handling rules).   Trying to mix the two things with those "blk_max_size_offset()" games  is just wrong.                      
If the controller interface is some 16-bit register, then the maximum  number of sectors you can specify is 65535.   But if the disk then doesn't like 512-byte accesses, but wants 4kB or  whatever, then clearly you can't actually *feed* it that maximum  number. Not because it's a maximal, but because it's not aligned.   But that doesn't mean that it's non-sensical. It just means that you  have to take both things into account.  There may be two totally  independent things that cause the two (very different) rules on what  the IO can look like.   Obviously there are probably games we could play, like always limiting  the maximum sector number to a multiple of the sector size. That would  presumably work for Stefan's case, by simply "artificially" making  max_sectors be 65528 instead.   But I do think it's better to consider them independent issues, and  just make sure that we always honor those things independently.   That "honor things independently" used to happen automatically before,  simply because we'd never split in the middle of a bio segment. And  since each bio segment was created with the limitations of the device  in mind, that all worked.   Now that it splits in the middle of a vector entry, that splitting  just needs to honor _all_ the rules. Not just the max sector one.   I suspect few high-performance controllers will really have big issues  with the max_sectors thing. If you have big enough IO that you could  hit the maximum sector number, you're already pretty well off, you  might as well split at that point.   So I think it's ok to split at the max sector case early.   For the case of nvme, for example, I think the max sector number is so  high that you'll never hit that anyway, and you'll only ever hit the  chunk limit. No?   So in practice it won't matter, I suspect.                    
It just doesn't look very legible.   Also, how could this   ever matter? If sectors is 0, something is seriously wrong afaik.                 
Not just conflict, but conflict in bad ways. I don't think I'll be  able to fix it up sanely.   In particular, commit b5875222de2f ("NVMe: IO ending fixes on surprise  removal") by Keith Busch added this to nvme_dev_remove():   and in your branch we now have:    - nvme_dev_shutdown() is now nvme_dev_disable(dev, false). Fine.    - nvme_dev_remove() got renamed to nvme_remove_namespaces(), but also  lost the "dev" argument (it takes "struct nvme_ctrl *ctrl" now).   I think I will end up doing the merge by just dropping that part of  the surprise removal commit, and letting you and Keith work out what  the real solution is..                    
Looks fine, if you can just fix this part:   and have it point to the public git://git.kernel.org/.. thing.   Either by just using "pushurl" for origin, or by having separate  push/pull names entirely.              
I have the ext4 pull pending now, I'm doing some test-builds before  pulling that and xfs. So it should be all done in half an hour or so.                 
Looks better, thanks.   I'd suggest also moving the "max_sectors" variable into the  bio_for_each_segment() loop too just to keep variables with minimal  scope, but at least this is fairly legible.   Also:   this could be written as   avoiding the extra shift. That also avoids the possible overflow that  that extra left-shift introduces. Hmm?                    
[ Grr. re-sending due to stupid html from android mobile app. ]   Why do you say that? It depends on the offset, so it clearly *does* change.   Now, if the patch did what I suggested and made max_sector and the cluster  size thing be separate, then *those* would indeed be constant over the whole  function.         
Ugh. Looks like valgrind is doing something that fundamentally can't  be "tweaked" around in the algorithm. Setting the data limit to zero  will never work with any model that starts accounting any mmap, so we  can't just tweak things a bit..   Hmm. If we start getting complaints from users, I suspect we'll just  have to revert. The fact that the valgrind developers are ok with the  change doesn't much matter - all that matters is whether users are ok  with it.   The only saving grace is that valgrind is fairly specialized, so it's  not like it breaks some core workflow. But I could easily see people  who run valgrind as part of some regression suite having their  day-to-day work broken.   So I'll let it slide for now, but if I start seeing complaints, I  think we'll just have to revert and wait for fixed valgrind versions  to actually percolate out to people and re-do it later.. (The  "percolate out to people" tends to take a _loong_ time, though).                    
This needs to be rewritten as an inline helper function or made  readable some other way.   It looks like line noise (or perl). That kind of code should not exist.                     
It's actually not a new patch - the patch (or rather, the script to  generate it - there's just a few small manual fixups for whitespace  etc that went along with it iirc) goes back almost a year by now, and  came about from a NFS "who owns the locking" discussion back then. It  was mainly with Neil Brown (who brought up a NFS performance issue).   I know you were involved in that thread at least tangentially too - we  talked about readdir() and how annoying the i_mutex is.   So the original script and patch were a "how about this" from me back  last spring.   And the whole "last day of the merge window" is actually intentional -  it's behind all the filesystem merges on purpose, so that there aren't  any merge conflicts from an almost entirely automated patch.   Side note: a large reason for the patch is exactly the fact that  particularly for things like filename lookup, the vfs layer really  needs to be in control of locking, and I disagreed violently with Neil  who thought the filesystem should be in control. We really have had  much better luck with trying to make sure that the vfs layer does a  reasonable job at locking than have each filesystem decide to do its  own thing.   But obviously, the inode semaphore is one of the weakest areas of the  vfs locking. I agree that it needs fixing, I just disagree violently  when somebody says "the vfs layer should get out of the way".   I know filesystem developers always think the buffering and the  caching that the vfs layer does is "not important", but that's because  you don't see the real work. Outside of some very specialized loads,  the cached cases are generally 99% of pretty much all loads, and it's  why doing things at the vfs layer (and the mm layer - the two are kind  of incestuous when it comes to things like the page cache) has been so  successful and important, and why I completely dismiss any "filesystem  should be in control" arguments. We used to do that, and it was a  nightmare.   Also, do note that the patch itself doesn't actually change locking at  all. It's purely about making it easier to slowly start changing the  locking by adding this abstraction layer that makes it possible to  change the lock type eventually. Al has some plans for (maybe) next  merge window, but for now it's all entirely syntactic preparation for  the future, no real change at all.                
You have some odd double-spacing issue in this pull request. It's  fine, and I pulled, but I thought I'd mention the oddity in case you  started doing something new and broken and hadn't noticed.                   
Ok, I am assuming this is in Andrew's queue already, but this bug hit  my machine overnight, so I'm applying it directly..                   
So the merge window is over, and rc1 is out there.  Go test!   It's a fairly normal release - neither unusually big or unusually  small. The statistics look fairly normal too, with drivers being a bit  over 70% of the bulk (the big driver areas being gpu, networking,  sound, staging, fbdev, but its all over). The shortlog is too big and  unwieldly to post, but I'm appending my "mergelog" which credits the  maintainers I merge from - not necessarily the people who did the  actual individual patches.   Aside from drivers, we have architecture updates (over half of it  being arm - both 32- and 64-bit this time around, the rest is powerpc,  x86, mips, s390). On the arch front, it's probably worth mentioning  that apparently the arm people have finalized their platform work, and  that you really can build a generic ARM kernel for all the ARMv6/7  platforms (and describe the hardware with devicetree). It's been many  years in coming. Good job.   There's also obviously the usual documentation, filesystem, generic  networking, and core kernel updates. A number of nice MM cleanuips  came in through Andrew this time around, for example, and Al Viro made  pathname lookup stay in RCU mode even over symlink traveral.   So there's a little something for anybody.                             Al Viro (10):    vfs compat_ioctl fixes    vfs RCU symlink updates    vfs xattr updates    vfs copy_file_range updates    iov_iter infrastructure updates    misc vfs updates    vfs fix    vfs regression fix    more vfs updates    final vfs updates   Alex Williamson (1):    VFIO updates   Alexandre Belloni (1):    RTC updates   Andrew Morton (5):    first patch-bomb    second patch-bomb    third patch-bomb    misc fixes    small final update   Arnd Bergmann (2):    asm-generic updates    ARM SoC multiplatform code updates   Bjorn Helgaas (1):    PCI updates   Bob Peterson (1):    GFS2 updates   Borislav Petkov (1):    EDAC updates   Brian Norris (1):    MTD updates   Bruce Fields (1):    nfsd updates   Chris Mason (2):    btrfs updates    more btrfs updates   Chris Metcalf (1):    arch/tile updates   Christoph Hellwig (1):    configfs updates   Corey Minyard (1):    ipmi updates   Dan Williams (1):    libnvdimm updates   Darren Hart (2):    x86 platform driver updates    more x86 platform driver updates   Dave Airlie (1):    drm updates   Dave Chinner (2):    xfs updates    more xfs updates   David Miller (5):    networking updates    sparc fixes    networking fixes    IDE updates    more networking fixes   David Vrabel (1):    xen updates   Dmitry Torokhov (2):    input updates    more input updates   Doug Ledford (1):    rdma updates   Eric Van Hensbergen (1):    9p updates   Geert Uytterhoeven (1):    m68k updates   Greg KH (4):    USB updates    tty/serial updates    staging driver updates    char/misc updates   Greg Ungerer (1):    m68knommu update   Guenter Roeck (1):    hwmon updates   Hans-Christian Noren Egtvedt (1):    AVR32 updates   Helge Deller (1):    parsic updates   Herbert Xu (2):    crypto update    crypto fixes   Ingo Molnar (16):    RCU updates    locking updates    perf updates    RAS updates    scheduler updates    x86 apic updates    x86 asm updates    small x86 boot update    x86 cleanups    x86 cpu updates    x86 fpu updates    x86 mm updates    x86 platform updates    perf fixes    timer fixes    x86 fixes   Jacek Anaszewski (1):    LED subsystem updates   Jaegeuk Kim (1):    f2fs updates   James Bottomley (2):    first round of SCSI updates    more SCSI updates   James Morris (2):    security subsystem updates    security subsystem update   Jan Kara (1):    UDF fixes and quota cleanups   Jean Delvare (1):    dmi updates   Jeff Layton (1):    file locking updates   Jens Axboe (4):    core block updates    block driver updates    lightnvm fixes and updates    NVMe updates   Jesper Nilsson (1):    CRIS updates   Jiri Kosina (3):    HID updates    livepatching updates    trivial tree updates   Joerg Roedel (1):    IOMMU updates   Jon Corbet (1):    documentation updates   Jon Mason (1):    NTB updates   Jussi Brar (1):    mailbox fixlet   Lee Jones (2):    backlight updates    MFD updates    Walleij (2):    pin control updates    GPIO updates   Mark Brown (3):    regmap updates    spi updates    regulator updates   Mark Salter (1):    tiny c6x update   Martin Schwidefsky (1):    s390 updates   Mauro Carvalho Chehab (2):    media updates    second batch of media updates   Michael Ellerman (1):    powerpc updates   Michael Tsirkin (1):    virtio barrier rework+fixes   Michael Turquette (1):    clk framework updates   Michal Marek (3):    kbuild updates    kconfig updates    misc kbuild updates   Mike Snitzer (1):    device mapper updates   Miklos Szeredi (2):    fuse updates    overlayfs updates   Neil Brown (1):    md updates   Nicholas Bellinger (1):    SCSI target updates   Olof Johansson (10):    non-urgent ARM SoC fixes    ARM SoC cleanups    ARM SoC platform updates    ARM DT updates    ARM 64-bit DT updates    ARM SoC defconfig updates    ARM 64-bit defconfig updates    ARM SoC driver updates    ARM SoC fixes    ARM SoC support for Tegra platforms   Paolo Bonzini (1):    KVM updates   Paul Moore (1):    audit updates   Rafael Wysocki (2):    oower management and ACPI updates    more power management and ACPI updates   Ralf Baechle (2):    MIPS fixes    MIPS updates   Richard Weinberger (2):    UML updates    UBI/UBIFS updates   Rob Herring (1):    DeviceTree updates   Russell King (2):    ARM updates    component updates   Sage Weil (1):    Ceph updates   Sebastian Reichel (2):    HSI updates    power supply and reset updates   Shuah Khan (1):    kselftest updates   Simon Horman (1):    SH driver updates   Steve French (1):    SMB3 fixes   Steven Rostedt (1):    tracing updates   Takashi Iwai (2):    sound updates    sound fixes   Ted Ts'o (1):    ext4 updates   Tejun Heo (4):    workqueue update    percpu updates    libata updates    cgroup updates   Thierry Reding (1):    pwm updates   Thomas Gleixner (2):    timer updates - and a leftover fix -    irq updates   Tomi Valkeinen (1):    fbdev updates   Tony Luck (2):    ia64 build fixes    ia64 copy_file_range syscall update   Trond Myklebust (2):    NFS client updates    NFS client bugfixes and cleanups   Ulf Hansson (2):    MMC updates    MMC fixes   Vinod Koul (2):    dmaengine updates    dmaengine fixes   Will Deacon (2):    arm64 updates    arm[64] perf updates   Wim Van Sebroeck (1):    watchdog updates   Wolfram Sang (1):    i2c updates   Yoshinori Sato (1):    h8300 updates   Zhang Rui (1):    thermal management updates
That may be distinct, but:   This case is complete BS. Stop perpetuating it. I already removed a  number of bogus cases of it, and I removed the incorrect documentation  that had this crap.   It's called "smp_READ_barrier_depends()" for a reason.   Alpha is the only one that needs it, and alpha needs it only for  dependent READS.   It's not called smp_read_write_barrier_depends(). It's not called  "smp_mb_depends()". It's a weaker form of "smp_rmb()", nothing else.   So alpha does have an implied dependency chain from a read to a  subsequent dependent write, and does not need any extra barriers.   Alpha does *not* have a dependency chain from a read to a subsequent  read, which is why we need that horrible crappy  smp_read_barrier_depends(). But it's the only reason.   This is the alpha reference manual wrt read-to-write dependency:     5.6.1.7 Definition of Dependence Constraint       The depends relation (DP) is defined as follows. Given u and v  issued by processor Pi, where u      is a read or an instruction fetch and v is a write, u precedes v  in DP order (written u DP v, that      is, v depends on u) in either of the following situations:        â u determines the execution of v, the location accessed by v, or  the value written by v.       â u determines the execution or address or value of another  memory access z that precedes       v or might precede v (that is, would precede v in some execution  path depending      on the value read by u) by processor issue constraint (see Section 5.6.1.3).   Note that the dependence barrier honors not only control flow, but  address and data values too.  This is a different syntax than we use,  but 'u' is the READ_ONCE, and 'v' is the write. Any data, address or  conditional dependency between the two implies an ordering.   So no, "smp_read_barrier_depends()" is *ONLY* about two reads, where  the second read is data-dependent on the first. Nothing else.   So if you _ever_ see a "smp_read_barrier_depends()" that isn't about a  barrier between two reads, then that is a bug.   The above code is crap.  It's exactly as much crap as   because a "rmb()" simply doesn't have anything to do with  read-vs-subsequent-write ordering.                    
You are entirely missing the point.   You might as well just write it as   because that "smp_read_barrier_depends()" does NOTHING wrt the second write.   So what I am saying is simple: anybody who writes that  "smp_read_barrier_depends()" in there is just ttoally and completely  WRONG, and the fact that Peter wrote it out after I removed several  instances of that bloody f*cking idiocy is disturbing.   Don't do it. It's BS. It's wrong. Don't make excuses for it.                
Just to clarify: on alpha it adds a memory barrier, but that memory  barrier is useless.   On non-alpha, it is a no-op, and obviously does nothing simply because  it generates no code.   So if anybody believes that the "smp_read_barrier_depends()" does  something, they are *wrong*.   And if anybody sends out an email with that smp_read_barrier_depends()  in an example, they are actively just confusing other people, which is  even worse than just being wrong. Which is why I jumped in.   So stop perpetuating the myth that smp_read_barrier_depends() does  something here. It does not. It's a bug, and it has become this "mind  virus" for some people that seem to believe that it does something.   I had to remove this crap once from the kernel already, see commit  105ff3cbf225 ("atomic: remove all traces of READ_ONCE_CTRL() and  atomic*_read_ctrl()").   I don't want to ever see that broken construct again. And I want to  make sure that everybody is educated about how broken it was. I'm  extremely unhappy that it came up again.   If it turns out that some architecture does actually need a barrier  between a read and a dependent write, then that will mean that    (a) we'll have to make up a _new_ barrier, because  "smp_read_barrier_depends()" is not that barrier. We'll presumably  then have to make that new barrier part of "rcu_derefence()" and  friends.    (b) we will have found an architecture with even worse memory  ordering semantics than alpha, and we'll have to stop castigating  alpha for being the worst memory ordering ever.   but I sincerely hope that we'll never find that kind of broken architecture.                  
I agree that that is likely the right thing to do in pretty much all situations.   In theory, there might be performance situations where we'd want to  actively avoid the smp_read_barrier_depends() inherent in those, but  considering that it's only a performance issue on alpha, and we  probably have all of two or three people using Linux on alpha, it's a  pretty theoretical performance worry.                     
So this doesn't look right for x86-64. Using %esp rather than %rsp.  How did that even work for you?                   
How the heck did you generate that diffstat? The names should be  ordered, and are for me.   Anyway, pulled. Just curious about how that thing happened.                
Ugh. I guess that makes sense, but it's still very annoying for  something like a pull request, where now different people end up  having different diffstats. And the reason I never noticed it is that  likely there aren't that many people who use an orderfile.   I guess something like "-O /dev/null" in the pull-request would undo  it, but it is a bit annoying.   I've never actually met anybody (knowingly) that used that option. I  thought it was a Junio-only use case (it's been around forever as a  command line option, but the config file entry seems to be somewhat  recent and I wasn't even aware of it).   Adding Junio just as background to see what he thinks. Looks like the   too.                 
Hmm. I may be missing something, but this still doesn't seem to have  commit 23688bf4f830 ("block: ensure to split after potentially  bouncing a bio"). It causes problems on x86-32 with PAE.   See also       https://bugzilla.kernel.org/show_bug.cgi?id=109661   but maybe the fix is there and I just didn't notice.                   
